## Классификация текстов.

[HTML](https://github.com/SvetlanaaIvanova/Practicum_projects/blob/main/Project%2010.%20Texts/%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2.html)

[ipynb](https://github.com/SvetlanaaIvanova/Practicum_projects/blob/main/Project%2010.%20Texts/%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2.ipynb)

### Описание проекта
Интернет-магазин запускает новый сервис: пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах, то есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. На основе набора данных (текстов комментариев) с разметкой о токсичности правок требуется обучить модель для классификации комментарии на позитивные и негативные.

### Навыки и инструменты
- python
- pandas
- numpy
- seaborn
- torch
- transformers
- wordcloud
- sklearn.model_selection
- sklearn.pipeline
- sklearn.linear_model
- sklearn.tree
- sklearn.svm
- sklearn.neighbors
- sklearn.metrics
- cnltk.tokenize
- nltk
- CountVectorizer 

### Общий вывод
Исходные комментарии в количестве 159292 обработаны моделью BERT. Для обучения и подбора лучшей модели отобраны случайным образом 500 строк, в том числе 400 включены в тренировочную выборку, а 100 - в тестовую. На отобранных данных проведено обучение 4 разных моделей машинного обучения с разными параметрами, в результате которого лучший результат по метрике точности f1 показала модель 6 ближайших соседей (f1-мера на тренировочной выборке показала результат, равный 0.94, а на тестовой - 0.77).
